{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2021/05/tuning-the-hyperparameters-and-layers-of-neural-network-deep-learning/\n",
    "# Bayesian Optimization(BO)\n",
    "# : Grid Search 처럼 모든 경우를 다 계산하는 것이 아니라, 몇개만 계산해서 objective function 의 최대 or 최소가 될 수 있는 hyperparameter 를 찾는 최적화기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from math import floor\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.layers import LeakyReLU\n",
    "LeakyReLU = LeakyReLU(alpha=0.1)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from numpy.random import seed # 예측 결과 일정하게 하기 위함\n",
    "seed(1) # 예측 결과 일정하게 하기 위함\n",
    "import tensorflow as tf  # 예측 결과 일정하게 하기 위함\n",
    "tf.random.set_seed(2) # 예측 결과 일정하게 하기 위함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code makes accuracy the scorer metric.\n",
    "\n",
    "score_acc = make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaddata set\n",
    "\n",
    "data = pd.read_csv(\"bladder_cancer.csv\")\n",
    "data.head(3)\n",
    "\n",
    "data = data.dropna()\n",
    "\n",
    "X = data.drop(columns=['Label'], axis=1)\n",
    "y = data['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set with cross-validation : test_set = 80 : 20 \n",
    "\n",
    "train_feature, test_feature, train_label, test_label = train_test_split(X, y, test_size = 0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature normalization, label 은 normalization 진행하지 않았음\n",
    "scaler = StandardScaler() # scaler 객체 생성\n",
    "scaler.fit(train_feature) # train_feature 의 mean 과 standard deviation 값을 추출\n",
    "train_feature_scaled = scaler.transform(train_feature) # train_feature 의 정규화 진행\n",
    "test_feature_scaled = scaler.transform(test_feature) # test_feature 의 정규화 진행.\n",
    "# test_feature 는 mean 과 standard deviation 값을 추출하는 과정 하면 안됨. \n",
    "# 학습할 때와 동일한 기반 설정으로 동일하게 테스트 데이터를 변환되야 함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas numpy 로 변환\n",
    "train_label = np.array(train_label)\n",
    "test_label = np.array(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haha = ['A','B','C']\n",
    "haha[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function\n",
    "def nn_cl_bo2(neurons_1st_hidden,neurons_other_hidden_1,neurons_other_hidden_2, learning_rate, batch_size, epochs,\n",
    "              layers1, layers2):\n",
    "   \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    neurons_1st_hidden = round(neurons_1st_hidden)\n",
    "    neurons_other_hidden_1 = round(neurons_other_hidden_1)\n",
    "    neurons_other_hidden_2 = round(neurons_other_hidden_2)\n",
    "    batch_size = round(batch_size)\n",
    "    epochs = round(epochs)\n",
    "    layers1 = round(layers1)\n",
    "    layers2 = round(layers2)\n",
    "    def nn_cl_fun():\n",
    "        nn = Sequential()\n",
    "        nn.add(Dense(neurons_1st_hidden, input_dim=10, activation='relu'))\n",
    "        for i in range(layers1):\n",
    "            nn.add(Dense(neurons_other_hidden_1, activation='relu'))\n",
    "        for i in range(layers2):\n",
    "            nn.add(Dense(neurons_other_hidden_2, activation='relu'))\n",
    "        nn.add(Dense(1, activation='sigmoid'))\n",
    "        nn.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        return nn\n",
    "    es = EarlyStopping(monitor='accuracy', mode='max', verbose=0, patience=10)\n",
    "    nn = KerasClassifier(build_fn=nn_cl_fun, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    score = cross_val_score(nn, train_feature_scaled, train_label, scoring=score_acc, cv=kfold, fit_params={'callbacks':[es]}).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | batch_... |  epochs   |  layers1  |  layers2  | learni... | neuron... | neuron... | neuron... |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000018EEB6E0040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8195  \u001b[0m | \u001b[0m 126.3   \u001b[0m | \u001b[0m 126.1   \u001b[0m | \u001b[0m 1.872   \u001b[0m | \u001b[0m 4.077   \u001b[0m | \u001b[0m 0.000302\u001b[0m | \u001b[0m 83.09   \u001b[0m | \u001b[0m 21.01   \u001b[0m | \u001b[0m 215.9   \u001b[0m |\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000018EEB64AB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.8565  \u001b[0m | \u001b[95m 55.35   \u001b[0m | \u001b[95m 201.9   \u001b[0m | \u001b[95m 2.981   \u001b[0m | \u001b[95m 1.951   \u001b[0m | \u001b[95m 9.038e-0\u001b[0m | \u001b[95m 338.1   \u001b[0m | \u001b[95m 314.4   \u001b[0m | \u001b[95m 144.4   \u001b[0m |\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8457  \u001b[0m | \u001b[0m 98.58   \u001b[0m | \u001b[0m 103.3   \u001b[0m | \u001b[0m 1.148   \u001b[0m | \u001b[0m 4.603   \u001b[0m | \u001b[0m 0.000796\u001b[0m | \u001b[0m 421.9   \u001b[0m | \u001b[0m 409.5   \u001b[0m | \u001b[0m 495.6   \u001b[0m |\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.8826  \u001b[0m | \u001b[95m 119.7   \u001b[0m | \u001b[95m 416.2   \u001b[0m | \u001b[95m 1.843   \u001b[0m | \u001b[95m 1.11    \u001b[0m | \u001b[95m 0.000459\u001b[0m | \u001b[95m 61.61   \u001b[0m | \u001b[95m 410.4   \u001b[0m | \u001b[95m 351.9   \u001b[0m |\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.878   \u001b[0m | \u001b[0m 117.4   \u001b[0m | \u001b[0m 173.4   \u001b[0m | \u001b[0m 2.997   \u001b[0m | \u001b[0m 1.552   \u001b[0m | \u001b[0m 0.000619\u001b[0m | \u001b[0m 247.7   \u001b[0m | \u001b[0m 208.5   \u001b[0m | \u001b[0m 366.6   \u001b[0m |\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.8778  \u001b[0m | \u001b[0m 71.33   \u001b[0m | \u001b[0m 230.2   \u001b[0m | \u001b[0m 1.638   \u001b[0m | \u001b[0m 4.789   \u001b[0m | \u001b[0m 0.000919\u001b[0m | \u001b[0m 408.8   \u001b[0m | \u001b[0m 26.7    \u001b[0m | \u001b[0m 472.3   \u001b[0m |\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.829   \u001b[0m | \u001b[0m 190.6   \u001b[0m | \u001b[0m 413.0   \u001b[0m | \u001b[0m 1.963   \u001b[0m | \u001b[0m 4.867   \u001b[0m | \u001b[0m 0.000422\u001b[0m | \u001b[0m 166.2   \u001b[0m | \u001b[0m 18.06   \u001b[0m | \u001b[0m 28.71   \u001b[0m |\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.8775  \u001b[0m | \u001b[0m 20.09   \u001b[0m | \u001b[0m 107.6   \u001b[0m | \u001b[0m 1.067   \u001b[0m | \u001b[0m 1.906   \u001b[0m | \u001b[0m 0.000548\u001b[0m | \u001b[0m 97.53   \u001b[0m | \u001b[0m 97.88   \u001b[0m | \u001b[0m 83.31   \u001b[0m |\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.8724  \u001b[0m | \u001b[0m 139.8   \u001b[0m | \u001b[0m 261.1   \u001b[0m | \u001b[0m 2.536   \u001b[0m | \u001b[0m 3.675   \u001b[0m | \u001b[0m 0.000446\u001b[0m | \u001b[0m 301.7   \u001b[0m | \u001b[0m 236.2   \u001b[0m | \u001b[0m 482.0   \u001b[0m |\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.8615  \u001b[0m | \u001b[0m 38.08   \u001b[0m | \u001b[0m 458.1   \u001b[0m | \u001b[0m 1.996   \u001b[0m | \u001b[0m 3.37    \u001b[0m | \u001b[0m 0.000687\u001b[0m | \u001b[0m 96.95   \u001b[0m | \u001b[0m 433.7   \u001b[0m | \u001b[0m 246.2   \u001b[0m |\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.8777  \u001b[0m | \u001b[0m 37.53   \u001b[0m | \u001b[0m 213.6   \u001b[0m | \u001b[0m 2.547   \u001b[0m | \u001b[0m 3.544   \u001b[0m | \u001b[0m 0.000177\u001b[0m | \u001b[0m 403.1   \u001b[0m | \u001b[0m 29.41   \u001b[0m | \u001b[0m 474.5   \u001b[0m |\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.8512  \u001b[0m | \u001b[0m 115.3   \u001b[0m | \u001b[0m 340.8   \u001b[0m | \u001b[0m 2.578   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.000263\u001b[0m | \u001b[0m 149.8   \u001b[0m | \u001b[0m 367.1   \u001b[0m | \u001b[0m 417.9   \u001b[0m |\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "| \u001b[95m 13      \u001b[0m | \u001b[95m 0.8881  \u001b[0m | \u001b[95m 50.24   \u001b[0m | \u001b[95m 414.1   \u001b[0m | \u001b[95m 2.504   \u001b[0m | \u001b[95m 1.416   \u001b[0m | \u001b[95m 0.000756\u001b[0m | \u001b[95m 130.9   \u001b[0m | \u001b[95m 386.6   \u001b[0m | \u001b[95m 482.1   \u001b[0m |\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "| \u001b[95m 14      \u001b[0m | \u001b[95m 0.9041  \u001b[0m | \u001b[95m 136.9   \u001b[0m | \u001b[95m 469.0   \u001b[0m | \u001b[95m 1.635   \u001b[0m | \u001b[95m 2.403   \u001b[0m | \u001b[95m 0.000630\u001b[0m | \u001b[95m 249.0   \u001b[0m | \u001b[95m 406.7   \u001b[0m | \u001b[95m 243.0   \u001b[0m |\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.8775  \u001b[0m | \u001b[0m 165.8   \u001b[0m | \u001b[0m 478.8   \u001b[0m | \u001b[0m 1.632   \u001b[0m | \u001b[0m 4.037   \u001b[0m | \u001b[0m 0.000787\u001b[0m | \u001b[0m 278.4   \u001b[0m | \u001b[0m 449.7   \u001b[0m | \u001b[0m 264.1   \u001b[0m |\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.8777  \u001b[0m | \u001b[0m 186.4   \u001b[0m | \u001b[0m 454.7   \u001b[0m | \u001b[0m 2.741   \u001b[0m | \u001b[0m 3.459   \u001b[0m | \u001b[0m 0.000279\u001b[0m | \u001b[0m 183.2   \u001b[0m | \u001b[0m 414.3   \u001b[0m | \u001b[0m 478.4   \u001b[0m |\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.8831  \u001b[0m | \u001b[0m 18.66   \u001b[0m | \u001b[0m 261.6   \u001b[0m | \u001b[0m 1.85    \u001b[0m | \u001b[0m 4.792   \u001b[0m | \u001b[0m 0.000861\u001b[0m | \u001b[0m 283.4   \u001b[0m | \u001b[0m 177.1   \u001b[0m | \u001b[0m 328.5   \u001b[0m |\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.8563  \u001b[0m | \u001b[0m 120.0   \u001b[0m | \u001b[0m 475.7   \u001b[0m | \u001b[0m 1.551   \u001b[0m | \u001b[0m 1.012   \u001b[0m | \u001b[0m 6.123e-0\u001b[0m | \u001b[0m 243.0   \u001b[0m | \u001b[0m 355.9   \u001b[0m | \u001b[0m 253.6   \u001b[0m |\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.8563  \u001b[0m | \u001b[0m 146.4   \u001b[0m | \u001b[0m 217.8   \u001b[0m | \u001b[0m 2.208   \u001b[0m | \u001b[0m 1.499   \u001b[0m | \u001b[0m 0.000613\u001b[0m | \u001b[0m 370.8   \u001b[0m | \u001b[0m 142.7   \u001b[0m | \u001b[0m 128.0   \u001b[0m |\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.8882  \u001b[0m | \u001b[0m 135.1   \u001b[0m | \u001b[0m 466.7   \u001b[0m | \u001b[0m 1.449   \u001b[0m | \u001b[0m 2.251   \u001b[0m | \u001b[0m 0.000168\u001b[0m | \u001b[0m 275.1   \u001b[0m | \u001b[0m 438.3   \u001b[0m | \u001b[0m 217.9   \u001b[0m |\n",
      "=========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# The following code searches for the optimum hyperparameters and layers for the Neural Network model\n",
    "params_nn2 ={\n",
    "    'neurons_1st_hidden': (10, 500),\n",
    "    'neurons_other_hidden_1':(10,500),\n",
    "    'neurons_other_hidden_2':(10,500),\n",
    "    'learning_rate':(0.00001, 0.001),\n",
    "    'batch_size':(10, 200),\n",
    "    'epochs':(50, 500),\n",
    "    'layers1':(1,3),\n",
    "    'layers2':(1,5),\n",
    "}\n",
    "# Run Bayesian Optimization\n",
    "# 'normalization':(0,1), # 이건 사용 안함\n",
    "\n",
    "nn_bo = BayesianOptimization(nn_cl_bo2, params_nn2, random_state=111)\n",
    "nn_bo.maximize(init_points=10, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 137,\n",
       " 'epochs': 469,\n",
       " 'layers1': 2,\n",
       " 'layers2': 2,\n",
       " 'learning_rate': 0.0006307808502973356,\n",
       " 'neurons_1st_hidden': 249,\n",
       " 'neurons_other_hidden_1': 407,\n",
       " 'neurons_other_hidden_2': 243}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Neural Network\n",
    "params_nn_ = nn_bo.max['params']\n",
    "learning_rate = params_nn_['learning_rate']\n",
    "params_nn_['batch_size'] = round(params_nn_['batch_size'])\n",
    "params_nn_['epochs'] = round(params_nn_['epochs'])\n",
    "params_nn_['layers1'] = round(params_nn_['layers1'])\n",
    "params_nn_['layers2'] = round(params_nn_['layers2'])\n",
    "params_nn_['neurons_1st_hidden'] = round(params_nn_['neurons_1st_hidden'])\n",
    "params_nn_['neurons_other_hidden_1'] = round(params_nn_['neurons_other_hidden_1'])\n",
    "params_nn_['neurons_other_hidden_2'] = round(params_nn_['neurons_other_hidden_2'])\n",
    "params_nn_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/469\n",
      "2/2 [==============================] - 1s 149ms/step - loss: 0.6930 - accuracy: 0.4556 - val_loss: 0.6761 - val_accuracy: 0.5789\n",
      "Epoch 2/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6398 - accuracy: 0.7101 - val_loss: 0.6373 - val_accuracy: 0.8421\n",
      "Epoch 3/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5827 - accuracy: 0.7929 - val_loss: 0.5886 - val_accuracy: 0.7895\n",
      "Epoch 4/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.5188 - accuracy: 0.8402 - val_loss: 0.5400 - val_accuracy: 0.7368\n",
      "Epoch 5/469\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4447 - accuracy: 0.8698 - val_loss: 0.4749 - val_accuracy: 0.7368\n",
      "Epoch 6/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3689 - accuracy: 0.8817 - val_loss: 0.4168 - val_accuracy: 0.7368\n",
      "Epoch 7/469\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3049 - accuracy: 0.9053 - val_loss: 0.3433 - val_accuracy: 0.8421\n",
      "Epoch 8/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.2577 - accuracy: 0.9172 - val_loss: 0.3154 - val_accuracy: 0.8421\n",
      "Epoch 9/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.2194 - accuracy: 0.9112 - val_loss: 0.3023 - val_accuracy: 0.8421\n",
      "Epoch 10/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1818 - accuracy: 0.9349 - val_loss: 0.2350 - val_accuracy: 0.8947\n",
      "Epoch 11/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.1531 - accuracy: 0.9527 - val_loss: 0.2325 - val_accuracy: 0.8421\n",
      "Epoch 12/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1232 - accuracy: 0.9763 - val_loss: 0.2334 - val_accuracy: 0.8421\n",
      "Epoch 13/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0967 - accuracy: 0.9822 - val_loss: 0.1516 - val_accuracy: 0.9474\n",
      "Epoch 14/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0809 - accuracy: 0.9822 - val_loss: 0.1063 - val_accuracy: 0.9474\n",
      "Epoch 15/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0568 - accuracy: 0.9882 - val_loss: 0.1691 - val_accuracy: 0.9474\n",
      "Epoch 16/469\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0445 - accuracy: 0.9822 - val_loss: 0.2160 - val_accuracy: 0.8947\n",
      "Epoch 17/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0364 - accuracy: 0.9941 - val_loss: 0.1367 - val_accuracy: 0.9474\n",
      "Epoch 18/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0272 - accuracy: 0.9941 - val_loss: 0.0950 - val_accuracy: 0.9474\n",
      "Epoch 19/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9474\n",
      "Epoch 20/469\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9474\n",
      "Epoch 21/469\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.1441 - val_accuracy: 0.9474\n",
      "Epoch 22/469\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1759 - val_accuracy: 0.9474\n",
      "Epoch 23/469\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1945 - val_accuracy: 0.9474\n",
      "Epoch 24/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2278 - val_accuracy: 0.9474\n",
      "Epoch 25/469\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2821 - val_accuracy: 0.9474\n",
      "Epoch 26/469\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.8947\n",
      "Epoch 27/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3801 - val_accuracy: 0.8947\n",
      "Epoch 28/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4255 - val_accuracy: 0.8947\n",
      "Epoch 29/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 8.6550e-04 - accuracy: 1.0000 - val_loss: 0.4644 - val_accuracy: 0.8947\n",
      "Epoch 30/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 7.4475e-04 - accuracy: 1.0000 - val_loss: 0.4932 - val_accuracy: 0.8947\n",
      "Epoch 31/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 6.5375e-04 - accuracy: 1.0000 - val_loss: 0.5123 - val_accuracy: 0.8947\n",
      "Epoch 32/469\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 5.8614e-04 - accuracy: 1.0000 - val_loss: 0.5296 - val_accuracy: 0.8947\n",
      "Epoch 33/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 5.2958e-04 - accuracy: 1.0000 - val_loss: 0.5443 - val_accuracy: 0.8421\n",
      "Epoch 34/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 4.7677e-04 - accuracy: 1.0000 - val_loss: 0.5540 - val_accuracy: 0.8421\n",
      "Epoch 35/469\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 4.2194e-04 - accuracy: 1.0000 - val_loss: 0.5596 - val_accuracy: 0.8421\n",
      "Epoch 36/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 3.6496e-04 - accuracy: 1.0000 - val_loss: 0.5595 - val_accuracy: 0.8421\n",
      "Epoch 37/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 3.1746e-04 - accuracy: 1.0000 - val_loss: 0.5529 - val_accuracy: 0.8421\n",
      "Epoch 38/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.8122e-04 - accuracy: 1.0000 - val_loss: 0.5457 - val_accuracy: 0.8421\n",
      "Epoch 39/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.5149e-04 - accuracy: 1.0000 - val_loss: 0.5443 - val_accuracy: 0.8421\n",
      "Epoch 40/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.2965e-04 - accuracy: 1.0000 - val_loss: 0.5468 - val_accuracy: 0.8421\n",
      "Epoch 41/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.1055e-04 - accuracy: 1.0000 - val_loss: 0.5502 - val_accuracy: 0.8421\n",
      "Epoch 42/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.9638e-04 - accuracy: 1.0000 - val_loss: 0.5537 - val_accuracy: 0.8421\n",
      "Epoch 43/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.8452e-04 - accuracy: 1.0000 - val_loss: 0.5550 - val_accuracy: 0.8421\n",
      "Epoch 44/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7405e-04 - accuracy: 1.0000 - val_loss: 0.5549 - val_accuracy: 0.8421\n",
      "Epoch 45/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6626e-04 - accuracy: 1.0000 - val_loss: 0.5523 - val_accuracy: 0.8421\n",
      "Epoch 46/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.5755e-04 - accuracy: 1.0000 - val_loss: 0.5465 - val_accuracy: 0.8421\n",
      "Epoch 47/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.5140e-04 - accuracy: 1.0000 - val_loss: 0.5412 - val_accuracy: 0.8421\n",
      "Epoch 48/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.4539e-04 - accuracy: 1.0000 - val_loss: 0.5379 - val_accuracy: 0.8421\n",
      "Epoch 49/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.3968e-04 - accuracy: 1.0000 - val_loss: 0.5360 - val_accuracy: 0.8421\n",
      "Epoch 50/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.3537e-04 - accuracy: 1.0000 - val_loss: 0.5346 - val_accuracy: 0.8421\n",
      "Epoch 51/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.3057e-04 - accuracy: 1.0000 - val_loss: 0.5332 - val_accuracy: 0.8421\n",
      "Epoch 52/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2656e-04 - accuracy: 1.0000 - val_loss: 0.5347 - val_accuracy: 0.8421\n",
      "Epoch 53/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.2243e-04 - accuracy: 1.0000 - val_loss: 0.5366 - val_accuracy: 0.8421\n",
      "Epoch 54/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.1908e-04 - accuracy: 1.0000 - val_loss: 0.5382 - val_accuracy: 0.8421\n",
      "Epoch 55/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.1543e-04 - accuracy: 1.0000 - val_loss: 0.5393 - val_accuracy: 0.8421\n",
      "Epoch 56/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.1223e-04 - accuracy: 1.0000 - val_loss: 0.5395 - val_accuracy: 0.8421\n",
      "Epoch 57/469\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.0909e-04 - accuracy: 1.0000 - val_loss: 0.5401 - val_accuracy: 0.8421\n",
      "Epoch 58/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.0648e-04 - accuracy: 1.0000 - val_loss: 0.5409 - val_accuracy: 0.8421\n",
      "Epoch 59/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.0357e-04 - accuracy: 1.0000 - val_loss: 0.5413 - val_accuracy: 0.8421\n",
      "Epoch 60/469\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.0123e-04 - accuracy: 1.0000 - val_loss: 0.5404 - val_accuracy: 0.8421\n",
      "Epoch 61/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 9.8400e-05 - accuracy: 1.0000 - val_loss: 0.5374 - val_accuracy: 0.8421\n",
      "Epoch 62/469\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 9.6131e-05 - accuracy: 1.0000 - val_loss: 0.5348 - val_accuracy: 0.8421\n",
      "Epoch 63/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 9.3955e-05 - accuracy: 1.0000 - val_loss: 0.5319 - val_accuracy: 0.8421\n",
      "Epoch 64/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 9.1710e-05 - accuracy: 1.0000 - val_loss: 0.5310 - val_accuracy: 0.8421\n",
      "Epoch 65/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 8.9670e-05 - accuracy: 1.0000 - val_loss: 0.5323 - val_accuracy: 0.8421\n",
      "Epoch 66/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 8.7783e-05 - accuracy: 1.0000 - val_loss: 0.5343 - val_accuracy: 0.8421\n",
      "Epoch 67/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 8.5732e-05 - accuracy: 1.0000 - val_loss: 0.5368 - val_accuracy: 0.8421\n",
      "Epoch 68/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 8.3960e-05 - accuracy: 1.0000 - val_loss: 0.5395 - val_accuracy: 0.8421\n",
      "Epoch 69/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 8.2361e-05 - accuracy: 1.0000 - val_loss: 0.5420 - val_accuracy: 0.8421\n",
      "Epoch 70/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 8.0655e-05 - accuracy: 1.0000 - val_loss: 0.5439 - val_accuracy: 0.8421\n",
      "Epoch 71/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 7.8943e-05 - accuracy: 1.0000 - val_loss: 0.5446 - val_accuracy: 0.8421\n",
      "Epoch 72/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 7.7494e-05 - accuracy: 1.0000 - val_loss: 0.5440 - val_accuracy: 0.8421\n",
      "Epoch 73/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 7.6002e-05 - accuracy: 1.0000 - val_loss: 0.5429 - val_accuracy: 0.8421\n",
      "Epoch 74/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 7.4441e-05 - accuracy: 1.0000 - val_loss: 0.5427 - val_accuracy: 0.8421\n",
      "Epoch 75/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 7.3148e-05 - accuracy: 1.0000 - val_loss: 0.5427 - val_accuracy: 0.8421\n",
      "Epoch 76/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 7.1802e-05 - accuracy: 1.0000 - val_loss: 0.5430 - val_accuracy: 0.8421\n",
      "Epoch 77/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 7.0571e-05 - accuracy: 1.0000 - val_loss: 0.5432 - val_accuracy: 0.8421\n",
      "Epoch 78/469\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 6.9187e-05 - accuracy: 1.0000 - val_loss: 0.5424 - val_accuracy: 0.8421\n",
      "Epoch 79/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 6.8040e-05 - accuracy: 1.0000 - val_loss: 0.5414 - val_accuracy: 0.8421\n",
      "Epoch 80/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 6.6804e-05 - accuracy: 1.0000 - val_loss: 0.5410 - val_accuracy: 0.8421\n",
      "Epoch 81/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 6.5669e-05 - accuracy: 1.0000 - val_loss: 0.5418 - val_accuracy: 0.8421\n",
      "Epoch 82/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 6.4472e-05 - accuracy: 1.0000 - val_loss: 0.5438 - val_accuracy: 0.8421\n",
      "Epoch 83/469\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 6.3364e-05 - accuracy: 1.0000 - val_loss: 0.5467 - val_accuracy: 0.8421\n",
      "Epoch 84/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 6.2118e-05 - accuracy: 1.0000 - val_loss: 0.5497 - val_accuracy: 0.8421\n",
      "Epoch 85/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 6.1043e-05 - accuracy: 1.0000 - val_loss: 0.5529 - val_accuracy: 0.8421\n",
      "Epoch 86/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 5.9875e-05 - accuracy: 1.0000 - val_loss: 0.5556 - val_accuracy: 0.8421\n",
      "Epoch 87/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 5.8745e-05 - accuracy: 1.0000 - val_loss: 0.5586 - val_accuracy: 0.8421\n",
      "Epoch 88/469\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 5.7746e-05 - accuracy: 1.0000 - val_loss: 0.5615 - val_accuracy: 0.8421\n",
      "Epoch 89/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 5.6749e-05 - accuracy: 1.0000 - val_loss: 0.5638 - val_accuracy: 0.8421\n",
      "Epoch 90/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 5.5732e-05 - accuracy: 1.0000 - val_loss: 0.5659 - val_accuracy: 0.8421\n",
      "Epoch 91/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 5.4756e-05 - accuracy: 1.0000 - val_loss: 0.5678 - val_accuracy: 0.8421\n",
      "Epoch 92/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 5.3839e-05 - accuracy: 1.0000 - val_loss: 0.5695 - val_accuracy: 0.8421\n",
      "Epoch 93/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 5.2955e-05 - accuracy: 1.0000 - val_loss: 0.5706 - val_accuracy: 0.8421\n",
      "Epoch 94/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 5.2101e-05 - accuracy: 1.0000 - val_loss: 0.5712 - val_accuracy: 0.8421\n",
      "Epoch 95/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 5.1164e-05 - accuracy: 1.0000 - val_loss: 0.5719 - val_accuracy: 0.8421\n",
      "Epoch 96/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 5.0326e-05 - accuracy: 1.0000 - val_loss: 0.5719 - val_accuracy: 0.8421\n",
      "Epoch 97/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 4.9491e-05 - accuracy: 1.0000 - val_loss: 0.5708 - val_accuracy: 0.8421\n",
      "Epoch 98/469\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 4.8649e-05 - accuracy: 1.0000 - val_loss: 0.5706 - val_accuracy: 0.8421\n",
      "Epoch 99/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 4.7759e-05 - accuracy: 1.0000 - val_loss: 0.5711 - val_accuracy: 0.8421\n",
      "Epoch 100/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 4.6981e-05 - accuracy: 1.0000 - val_loss: 0.5724 - val_accuracy: 0.8421\n",
      "Epoch 101/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 4.6160e-05 - accuracy: 1.0000 - val_loss: 0.5742 - val_accuracy: 0.8421\n",
      "Epoch 102/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 4.5419e-05 - accuracy: 1.0000 - val_loss: 0.5768 - val_accuracy: 0.8421\n",
      "Epoch 103/469\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 4.4653e-05 - accuracy: 1.0000 - val_loss: 0.5791 - val_accuracy: 0.8421\n",
      "Epoch 104/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 4.3910e-05 - accuracy: 1.0000 - val_loss: 0.5813 - val_accuracy: 0.8421\n",
      "Epoch 105/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 4.3158e-05 - accuracy: 1.0000 - val_loss: 0.5834 - val_accuracy: 0.8421\n",
      "Epoch 106/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 4.2522e-05 - accuracy: 1.0000 - val_loss: 0.5840 - val_accuracy: 0.8421\n",
      "Epoch 107/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 4.1867e-05 - accuracy: 1.0000 - val_loss: 0.5830 - val_accuracy: 0.8421\n",
      "Epoch 108/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 4.1157e-05 - accuracy: 1.0000 - val_loss: 0.5815 - val_accuracy: 0.8421\n",
      "Epoch 109/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 4.0538e-05 - accuracy: 1.0000 - val_loss: 0.5793 - val_accuracy: 0.8421\n",
      "Epoch 110/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 3.9956e-05 - accuracy: 1.0000 - val_loss: 0.5779 - val_accuracy: 0.8421\n",
      "Epoch 111/469\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 3.9358e-05 - accuracy: 1.0000 - val_loss: 0.5783 - val_accuracy: 0.8421\n",
      "Epoch 112/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 3.8777e-05 - accuracy: 1.0000 - val_loss: 0.5796 - val_accuracy: 0.8421\n",
      "Epoch 113/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 3.8118e-05 - accuracy: 1.0000 - val_loss: 0.5808 - val_accuracy: 0.8421\n",
      "Epoch 114/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 3.7606e-05 - accuracy: 1.0000 - val_loss: 0.5817 - val_accuracy: 0.8421\n",
      "Epoch 115/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 3.7023e-05 - accuracy: 1.0000 - val_loss: 0.5819 - val_accuracy: 0.8421\n",
      "Epoch 116/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 3.6403e-05 - accuracy: 1.0000 - val_loss: 0.5830 - val_accuracy: 0.8421\n",
      "Epoch 117/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 3.5843e-05 - accuracy: 1.0000 - val_loss: 0.5855 - val_accuracy: 0.8421\n",
      "Epoch 118/469\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 3.5313e-05 - accuracy: 1.0000 - val_loss: 0.5883 - val_accuracy: 0.8421\n",
      "Epoch 119/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 3.4754e-05 - accuracy: 1.0000 - val_loss: 0.5911 - val_accuracy: 0.8421\n",
      "Epoch 120/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 3.4255e-05 - accuracy: 1.0000 - val_loss: 0.5934 - val_accuracy: 0.8421\n",
      "Epoch 121/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 3.3679e-05 - accuracy: 1.0000 - val_loss: 0.5964 - val_accuracy: 0.8421\n",
      "Epoch 122/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 3.3196e-05 - accuracy: 1.0000 - val_loss: 0.6004 - val_accuracy: 0.8421\n",
      "Epoch 123/469\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 3.2735e-05 - accuracy: 1.0000 - val_loss: 0.6046 - val_accuracy: 0.8421\n",
      "Epoch 124/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 3.2254e-05 - accuracy: 1.0000 - val_loss: 0.6085 - val_accuracy: 0.8421\n",
      "Epoch 125/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 3.1776e-05 - accuracy: 1.0000 - val_loss: 0.6108 - val_accuracy: 0.8421\n",
      "Epoch 126/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 3.1358e-05 - accuracy: 1.0000 - val_loss: 0.6112 - val_accuracy: 0.8421\n",
      "Epoch 127/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 3.0863e-05 - accuracy: 1.0000 - val_loss: 0.6115 - val_accuracy: 0.8421\n",
      "Epoch 128/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 3.0442e-05 - accuracy: 1.0000 - val_loss: 0.6126 - val_accuracy: 0.8421\n",
      "Epoch 129/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 3.0012e-05 - accuracy: 1.0000 - val_loss: 0.6140 - val_accuracy: 0.8421\n",
      "Epoch 130/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.9574e-05 - accuracy: 1.0000 - val_loss: 0.6159 - val_accuracy: 0.8421\n",
      "Epoch 131/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.9129e-05 - accuracy: 1.0000 - val_loss: 0.6178 - val_accuracy: 0.8421\n",
      "Epoch 132/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.8720e-05 - accuracy: 1.0000 - val_loss: 0.6196 - val_accuracy: 0.8421\n",
      "Epoch 133/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.8286e-05 - accuracy: 1.0000 - val_loss: 0.6224 - val_accuracy: 0.8421\n",
      "Epoch 134/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.7911e-05 - accuracy: 1.0000 - val_loss: 0.6244 - val_accuracy: 0.8421\n",
      "Epoch 135/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.7480e-05 - accuracy: 1.0000 - val_loss: 0.6251 - val_accuracy: 0.8421\n",
      "Epoch 136/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.7094e-05 - accuracy: 1.0000 - val_loss: 0.6249 - val_accuracy: 0.8421\n",
      "Epoch 137/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.6694e-05 - accuracy: 1.0000 - val_loss: 0.6246 - val_accuracy: 0.8421\n",
      "Epoch 138/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.6328e-05 - accuracy: 1.0000 - val_loss: 0.6237 - val_accuracy: 0.8421\n",
      "Epoch 139/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.5968e-05 - accuracy: 1.0000 - val_loss: 0.6221 - val_accuracy: 0.8421\n",
      "Epoch 140/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.5631e-05 - accuracy: 1.0000 - val_loss: 0.6204 - val_accuracy: 0.8421\n",
      "Epoch 141/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.5290e-05 - accuracy: 1.0000 - val_loss: 0.6187 - val_accuracy: 0.8421\n",
      "Epoch 142/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.4956e-05 - accuracy: 1.0000 - val_loss: 0.6176 - val_accuracy: 0.8421\n",
      "Epoch 143/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.4646e-05 - accuracy: 1.0000 - val_loss: 0.6167 - val_accuracy: 0.8421\n",
      "Epoch 144/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.4288e-05 - accuracy: 1.0000 - val_loss: 0.6174 - val_accuracy: 0.8421\n",
      "Epoch 145/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.4009e-05 - accuracy: 1.0000 - val_loss: 0.6191 - val_accuracy: 0.8421\n",
      "Epoch 146/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.3651e-05 - accuracy: 1.0000 - val_loss: 0.6212 - val_accuracy: 0.8421\n",
      "Epoch 147/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.3315e-05 - accuracy: 1.0000 - val_loss: 0.6231 - val_accuracy: 0.8421\n",
      "Epoch 148/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.2970e-05 - accuracy: 1.0000 - val_loss: 0.6258 - val_accuracy: 0.8421\n",
      "Epoch 149/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.2675e-05 - accuracy: 1.0000 - val_loss: 0.6297 - val_accuracy: 0.8421\n",
      "Epoch 150/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.2333e-05 - accuracy: 1.0000 - val_loss: 0.6347 - val_accuracy: 0.8421\n",
      "Epoch 151/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.2030e-05 - accuracy: 1.0000 - val_loss: 0.6392 - val_accuracy: 0.8421\n",
      "Epoch 152/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.1750e-05 - accuracy: 1.0000 - val_loss: 0.6432 - val_accuracy: 0.8421\n",
      "Epoch 153/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.1403e-05 - accuracy: 1.0000 - val_loss: 0.6466 - val_accuracy: 0.8421\n",
      "Epoch 154/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.1136e-05 - accuracy: 1.0000 - val_loss: 0.6497 - val_accuracy: 0.8421\n",
      "Epoch 155/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.0812e-05 - accuracy: 1.0000 - val_loss: 0.6531 - val_accuracy: 0.8421\n",
      "Epoch 156/469\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.0546e-05 - accuracy: 1.0000 - val_loss: 0.6567 - val_accuracy: 0.8421\n",
      "Epoch 157/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.0290e-05 - accuracy: 1.0000 - val_loss: 0.6605 - val_accuracy: 0.8421\n",
      "Epoch 158/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.0004e-05 - accuracy: 1.0000 - val_loss: 0.6617 - val_accuracy: 0.8421\n",
      "Epoch 159/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.9753e-05 - accuracy: 1.0000 - val_loss: 0.6601 - val_accuracy: 0.8421\n",
      "Epoch 160/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.9475e-05 - accuracy: 1.0000 - val_loss: 0.6583 - val_accuracy: 0.8421\n",
      "Epoch 161/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.9212e-05 - accuracy: 1.0000 - val_loss: 0.6576 - val_accuracy: 0.8421\n",
      "Epoch 162/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.8965e-05 - accuracy: 1.0000 - val_loss: 0.6579 - val_accuracy: 0.8421\n",
      "Epoch 163/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.8713e-05 - accuracy: 1.0000 - val_loss: 0.6585 - val_accuracy: 0.8421\n",
      "Epoch 164/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.8457e-05 - accuracy: 1.0000 - val_loss: 0.6593 - val_accuracy: 0.8421\n",
      "Epoch 165/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.8215e-05 - accuracy: 1.0000 - val_loss: 0.6605 - val_accuracy: 0.8421\n",
      "Epoch 166/469\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.7976e-05 - accuracy: 1.0000 - val_loss: 0.6614 - val_accuracy: 0.8421\n",
      "Epoch 167/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7754e-05 - accuracy: 1.0000 - val_loss: 0.6626 - val_accuracy: 0.8421\n",
      "Epoch 168/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7536e-05 - accuracy: 1.0000 - val_loss: 0.6636 - val_accuracy: 0.8421\n",
      "Epoch 169/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.7302e-05 - accuracy: 1.0000 - val_loss: 0.6634 - val_accuracy: 0.8421\n",
      "Epoch 170/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7104e-05 - accuracy: 1.0000 - val_loss: 0.6635 - val_accuracy: 0.8421\n",
      "Epoch 171/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.6885e-05 - accuracy: 1.0000 - val_loss: 0.6636 - val_accuracy: 0.8421\n",
      "Epoch 172/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6650e-05 - accuracy: 1.0000 - val_loss: 0.6652 - val_accuracy: 0.8421\n",
      "Epoch 173/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6474e-05 - accuracy: 1.0000 - val_loss: 0.6678 - val_accuracy: 0.8421\n",
      "Epoch 174/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6260e-05 - accuracy: 1.0000 - val_loss: 0.6701 - val_accuracy: 0.8421\n",
      "Epoch 175/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6066e-05 - accuracy: 1.0000 - val_loss: 0.6730 - val_accuracy: 0.8421\n",
      "Epoch 176/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5872e-05 - accuracy: 1.0000 - val_loss: 0.6748 - val_accuracy: 0.8421\n",
      "Epoch 177/469\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.5667e-05 - accuracy: 1.0000 - val_loss: 0.6767 - val_accuracy: 0.8421\n",
      "Epoch 178/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.5477e-05 - accuracy: 1.0000 - val_loss: 0.6802 - val_accuracy: 0.8421\n",
      "Epoch 179/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.5286e-05 - accuracy: 1.0000 - val_loss: 0.6856 - val_accuracy: 0.8421\n",
      "Epoch 180/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.5076e-05 - accuracy: 1.0000 - val_loss: 0.6909 - val_accuracy: 0.8421\n",
      "Epoch 181/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.4881e-05 - accuracy: 1.0000 - val_loss: 0.6960 - val_accuracy: 0.8421\n",
      "Epoch 182/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.4698e-05 - accuracy: 1.0000 - val_loss: 0.6998 - val_accuracy: 0.8421\n",
      "Epoch 183/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.4512e-05 - accuracy: 1.0000 - val_loss: 0.7025 - val_accuracy: 0.8421\n",
      "Epoch 184/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.4319e-05 - accuracy: 1.0000 - val_loss: 0.7051 - val_accuracy: 0.8421\n",
      "Epoch 185/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.4134e-05 - accuracy: 1.0000 - val_loss: 0.7068 - val_accuracy: 0.8421\n",
      "Epoch 186/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.3943e-05 - accuracy: 1.0000 - val_loss: 0.7091 - val_accuracy: 0.8421\n",
      "Epoch 187/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.3783e-05 - accuracy: 1.0000 - val_loss: 0.7128 - val_accuracy: 0.8421\n",
      "Epoch 188/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.3599e-05 - accuracy: 1.0000 - val_loss: 0.7164 - val_accuracy: 0.8421\n",
      "Epoch 189/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.3442e-05 - accuracy: 1.0000 - val_loss: 0.7197 - val_accuracy: 0.8421\n",
      "Epoch 190/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.3284e-05 - accuracy: 1.0000 - val_loss: 0.7227 - val_accuracy: 0.8421\n",
      "Epoch 191/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.3124e-05 - accuracy: 1.0000 - val_loss: 0.7256 - val_accuracy: 0.8421\n",
      "Epoch 192/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2969e-05 - accuracy: 1.0000 - val_loss: 0.7280 - val_accuracy: 0.8421\n",
      "Epoch 193/469\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.2838e-05 - accuracy: 1.0000 - val_loss: 0.7311 - val_accuracy: 0.8421\n",
      "Epoch 194/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.2689e-05 - accuracy: 1.0000 - val_loss: 0.7338 - val_accuracy: 0.8421\n",
      "Epoch 195/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.2547e-05 - accuracy: 1.0000 - val_loss: 0.7357 - val_accuracy: 0.8421\n",
      "Epoch 196/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.2408e-05 - accuracy: 1.0000 - val_loss: 0.7389 - val_accuracy: 0.8421\n",
      "Epoch 197/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.2244e-05 - accuracy: 1.0000 - val_loss: 0.7441 - val_accuracy: 0.8421\n",
      "Epoch 198/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.2077e-05 - accuracy: 1.0000 - val_loss: 0.7528 - val_accuracy: 0.8421\n",
      "Epoch 199/469\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.1869e-05 - accuracy: 1.0000 - val_loss: 0.7622 - val_accuracy: 0.8421\n",
      "Epoch 200/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.1759e-05 - accuracy: 1.0000 - val_loss: 0.7693 - val_accuracy: 0.8421\n",
      "Epoch 201/469\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.1645e-05 - accuracy: 1.0000 - val_loss: 0.7700 - val_accuracy: 0.8421\n",
      "Epoch 202/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.1493e-05 - accuracy: 1.0000 - val_loss: 0.7646 - val_accuracy: 0.8421\n",
      "Epoch 203/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.1329e-05 - accuracy: 1.0000 - val_loss: 0.7599 - val_accuracy: 0.8421\n",
      "Epoch 204/469\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.1204e-05 - accuracy: 1.0000 - val_loss: 0.7569 - val_accuracy: 0.8421\n",
      "Epoch 205/469\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.1092e-05 - accuracy: 1.0000 - val_loss: 0.7550 - val_accuracy: 0.8421\n",
      "Epoch 206/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0992e-05 - accuracy: 1.0000 - val_loss: 0.7556 - val_accuracy: 0.8421\n",
      "Epoch 207/469\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.0877e-05 - accuracy: 1.0000 - val_loss: 0.7588 - val_accuracy: 0.8421\n",
      "Epoch 208/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.0747e-05 - accuracy: 1.0000 - val_loss: 0.7642 - val_accuracy: 0.8421\n",
      "Epoch 209/469\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.0625e-05 - accuracy: 1.0000 - val_loss: 0.7711 - val_accuracy: 0.8421\n",
      "Epoch 210/469\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.0492e-05 - accuracy: 1.0000 - val_loss: 0.7780 - val_accuracy: 0.8421\n",
      "Epoch 211/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.0367e-05 - accuracy: 1.0000 - val_loss: 0.7844 - val_accuracy: 0.8421\n",
      "Epoch 212/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.0250e-05 - accuracy: 1.0000 - val_loss: 0.7901 - val_accuracy: 0.8421\n",
      "Epoch 213/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.0111e-05 - accuracy: 1.0000 - val_loss: 0.7973 - val_accuracy: 0.8421\n",
      "Epoch 214/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.0004e-05 - accuracy: 1.0000 - val_loss: 0.8048 - val_accuracy: 0.8421\n",
      "Epoch 215/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 9.8616e-06 - accuracy: 1.0000 - val_loss: 0.8126 - val_accuracy: 0.8421\n",
      "Epoch 216/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 9.7383e-06 - accuracy: 1.0000 - val_loss: 0.8216 - val_accuracy: 0.8421\n",
      "Epoch 217/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 9.6108e-06 - accuracy: 1.0000 - val_loss: 0.8311 - val_accuracy: 0.8421\n",
      "Epoch 218/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 9.5008e-06 - accuracy: 1.0000 - val_loss: 0.8379 - val_accuracy: 0.8421\n",
      "Epoch 219/469\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 9.3809e-06 - accuracy: 1.0000 - val_loss: 0.8416 - val_accuracy: 0.8421\n",
      "Epoch 220/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 9.2728e-06 - accuracy: 1.0000 - val_loss: 0.8406 - val_accuracy: 0.8421\n",
      "Epoch 221/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 9.1576e-06 - accuracy: 1.0000 - val_loss: 0.8360 - val_accuracy: 0.8421\n",
      "Epoch 222/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 9.0467e-06 - accuracy: 1.0000 - val_loss: 0.8342 - val_accuracy: 0.8421\n",
      "Epoch 223/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 8.9463e-06 - accuracy: 1.0000 - val_loss: 0.8356 - val_accuracy: 0.8421\n",
      "Epoch 224/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 8.8336e-06 - accuracy: 1.0000 - val_loss: 0.8409 - val_accuracy: 0.8421\n",
      "Epoch 225/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 8.7266e-06 - accuracy: 1.0000 - val_loss: 0.8475 - val_accuracy: 0.8421\n",
      "Epoch 226/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 8.6134e-06 - accuracy: 1.0000 - val_loss: 0.8523 - val_accuracy: 0.8421\n",
      "Epoch 227/469\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 8.5000e-06 - accuracy: 1.0000 - val_loss: 0.8552 - val_accuracy: 0.8421\n",
      "Epoch 228/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 8.4109e-06 - accuracy: 1.0000 - val_loss: 0.8579 - val_accuracy: 0.8421\n",
      "Epoch 229/469\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 8.3213e-06 - accuracy: 1.0000 - val_loss: 0.8591 - val_accuracy: 0.8421\n",
      "Epoch 230/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 8.2309e-06 - accuracy: 1.0000 - val_loss: 0.8596 - val_accuracy: 0.8421\n",
      "Epoch 231/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 8.1438e-06 - accuracy: 1.0000 - val_loss: 0.8596 - val_accuracy: 0.8421\n",
      "Epoch 232/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 8.0589e-06 - accuracy: 1.0000 - val_loss: 0.8580 - val_accuracy: 0.8421\n",
      "Epoch 233/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 7.9794e-06 - accuracy: 1.0000 - val_loss: 0.8557 - val_accuracy: 0.8421\n",
      "Epoch 234/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 7.8936e-06 - accuracy: 1.0000 - val_loss: 0.8564 - val_accuracy: 0.8421\n",
      "Epoch 235/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 7.8058e-06 - accuracy: 1.0000 - val_loss: 0.8600 - val_accuracy: 0.8421\n",
      "Epoch 236/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 7.7290e-06 - accuracy: 1.0000 - val_loss: 0.8624 - val_accuracy: 0.8421\n",
      "Epoch 237/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 7.6456e-06 - accuracy: 1.0000 - val_loss: 0.8636 - val_accuracy: 0.8421\n",
      "Epoch 238/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 7.5750e-06 - accuracy: 1.0000 - val_loss: 0.8664 - val_accuracy: 0.8421\n",
      "Epoch 239/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 7.5030e-06 - accuracy: 1.0000 - val_loss: 0.8665 - val_accuracy: 0.8421\n",
      "Epoch 240/469\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 7.4168e-06 - accuracy: 1.0000 - val_loss: 0.8629 - val_accuracy: 0.8421\n",
      "Epoch 241/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 7.3498e-06 - accuracy: 1.0000 - val_loss: 0.8596 - val_accuracy: 0.8421\n",
      "Epoch 242/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 7.2832e-06 - accuracy: 1.0000 - val_loss: 0.8596 - val_accuracy: 0.8421\n",
      "Epoch 243/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 7.2160e-06 - accuracy: 1.0000 - val_loss: 0.8607 - val_accuracy: 0.8421\n",
      "Epoch 244/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 7.1426e-06 - accuracy: 1.0000 - val_loss: 0.8645 - val_accuracy: 0.8421\n",
      "Epoch 245/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 7.0737e-06 - accuracy: 1.0000 - val_loss: 0.8705 - val_accuracy: 0.8421\n",
      "Epoch 246/469\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 6.9962e-06 - accuracy: 1.0000 - val_loss: 0.8759 - val_accuracy: 0.8421\n",
      "Epoch 247/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 6.9336e-06 - accuracy: 1.0000 - val_loss: 0.8790 - val_accuracy: 0.8421\n",
      "Epoch 248/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 6.8565e-06 - accuracy: 1.0000 - val_loss: 0.8788 - val_accuracy: 0.8421\n",
      "Epoch 249/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 6.7782e-06 - accuracy: 1.0000 - val_loss: 0.8767 - val_accuracy: 0.8421\n",
      "Epoch 250/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 6.7291e-06 - accuracy: 1.0000 - val_loss: 0.8732 - val_accuracy: 0.8421\n",
      "Epoch 251/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 6.6749e-06 - accuracy: 1.0000 - val_loss: 0.8717 - val_accuracy: 0.8421\n",
      "Epoch 252/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 6.6122e-06 - accuracy: 1.0000 - val_loss: 0.8738 - val_accuracy: 0.8421\n",
      "Epoch 253/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 6.5343e-06 - accuracy: 1.0000 - val_loss: 0.8755 - val_accuracy: 0.8421\n",
      "Epoch 254/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 6.4600e-06 - accuracy: 1.0000 - val_loss: 0.8762 - val_accuracy: 0.8421\n",
      "Epoch 255/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 6.3994e-06 - accuracy: 1.0000 - val_loss: 0.8750 - val_accuracy: 0.8421\n",
      "Epoch 256/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 6.3293e-06 - accuracy: 1.0000 - val_loss: 0.8728 - val_accuracy: 0.8421\n",
      "Epoch 257/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 6.2708e-06 - accuracy: 1.0000 - val_loss: 0.8709 - val_accuracy: 0.8421\n",
      "Epoch 258/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 6.2127e-06 - accuracy: 1.0000 - val_loss: 0.8705 - val_accuracy: 0.8421\n",
      "Epoch 259/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 6.1628e-06 - accuracy: 1.0000 - val_loss: 0.8703 - val_accuracy: 0.8421\n",
      "Epoch 260/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 6.0869e-06 - accuracy: 1.0000 - val_loss: 0.8674 - val_accuracy: 0.8421\n",
      "Epoch 261/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 6.0322e-06 - accuracy: 1.0000 - val_loss: 0.8666 - val_accuracy: 0.8421\n",
      "Epoch 262/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 5.9797e-06 - accuracy: 1.0000 - val_loss: 0.8680 - val_accuracy: 0.8421\n",
      "Epoch 263/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 5.9159e-06 - accuracy: 1.0000 - val_loss: 0.8734 - val_accuracy: 0.8421\n",
      "Epoch 264/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 5.8511e-06 - accuracy: 1.0000 - val_loss: 0.8810 - val_accuracy: 0.8421\n",
      "Epoch 265/469\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 5.7889e-06 - accuracy: 1.0000 - val_loss: 0.8880 - val_accuracy: 0.8421\n",
      "Epoch 266/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 5.7348e-06 - accuracy: 1.0000 - val_loss: 0.8946 - val_accuracy: 0.8421\n",
      "Epoch 267/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 5.6904e-06 - accuracy: 1.0000 - val_loss: 0.9005 - val_accuracy: 0.8421\n",
      "Epoch 268/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 5.6453e-06 - accuracy: 1.0000 - val_loss: 0.9033 - val_accuracy: 0.8421\n",
      "Epoch 269/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 5.5924e-06 - accuracy: 1.0000 - val_loss: 0.9034 - val_accuracy: 0.8421\n",
      "Epoch 270/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 5.5360e-06 - accuracy: 1.0000 - val_loss: 0.9036 - val_accuracy: 0.8421\n",
      "Epoch 271/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 5.4852e-06 - accuracy: 1.0000 - val_loss: 0.9046 - val_accuracy: 0.8421\n",
      "Epoch 272/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 5.4307e-06 - accuracy: 1.0000 - val_loss: 0.9048 - val_accuracy: 0.8421\n",
      "Epoch 273/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 5.3856e-06 - accuracy: 1.0000 - val_loss: 0.9045 - val_accuracy: 0.8421\n",
      "Epoch 274/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 5.3377e-06 - accuracy: 1.0000 - val_loss: 0.9056 - val_accuracy: 0.8421\n",
      "Epoch 275/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 5.2913e-06 - accuracy: 1.0000 - val_loss: 0.9051 - val_accuracy: 0.8421\n",
      "Epoch 276/469\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 5.2292e-06 - accuracy: 1.0000 - val_loss: 0.9043 - val_accuracy: 0.8421\n",
      "Epoch 277/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 5.1781e-06 - accuracy: 1.0000 - val_loss: 0.9059 - val_accuracy: 0.8421\n",
      "Epoch 278/469\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 5.1217e-06 - accuracy: 1.0000 - val_loss: 0.9078 - val_accuracy: 0.8421\n",
      "Epoch 279/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 5.0763e-06 - accuracy: 1.0000 - val_loss: 0.9052 - val_accuracy: 0.8421\n",
      "Epoch 280/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 5.0194e-06 - accuracy: 1.0000 - val_loss: 0.8984 - val_accuracy: 0.8421\n",
      "Epoch 281/469\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 4.9760e-06 - accuracy: 1.0000 - val_loss: 0.8926 - val_accuracy: 0.8421\n",
      "Epoch 282/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 4.9326e-06 - accuracy: 1.0000 - val_loss: 0.8884 - val_accuracy: 0.8421\n",
      "Epoch 283/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 4.8887e-06 - accuracy: 1.0000 - val_loss: 0.8844 - val_accuracy: 0.8421\n",
      "Epoch 284/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 4.8483e-06 - accuracy: 1.0000 - val_loss: 0.8801 - val_accuracy: 0.8421\n",
      "Epoch 285/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 4.8055e-06 - accuracy: 1.0000 - val_loss: 0.8754 - val_accuracy: 0.8421\n",
      "Epoch 286/469\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 4.7692e-06 - accuracy: 1.0000 - val_loss: 0.8720 - val_accuracy: 0.8421\n",
      "Epoch 287/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 4.7252e-06 - accuracy: 1.0000 - val_loss: 0.8707 - val_accuracy: 0.8421\n",
      "Epoch 288/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 4.6845e-06 - accuracy: 1.0000 - val_loss: 0.8713 - val_accuracy: 0.8421\n",
      "Epoch 289/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 4.6396e-06 - accuracy: 1.0000 - val_loss: 0.8736 - val_accuracy: 0.8421\n",
      "Epoch 290/469\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 4.5993e-06 - accuracy: 1.0000 - val_loss: 0.8752 - val_accuracy: 0.8421\n",
      "Epoch 291/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 4.5609e-06 - accuracy: 1.0000 - val_loss: 0.8747 - val_accuracy: 0.8421\n",
      "Epoch 292/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 4.5236e-06 - accuracy: 1.0000 - val_loss: 0.8746 - val_accuracy: 0.8421\n",
      "Epoch 293/469\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 4.4886e-06 - accuracy: 1.0000 - val_loss: 0.8738 - val_accuracy: 0.8421\n",
      "Epoch 294/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 4.4535e-06 - accuracy: 1.0000 - val_loss: 0.8729 - val_accuracy: 0.8421\n",
      "Epoch 295/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 4.4184e-06 - accuracy: 1.0000 - val_loss: 0.8729 - val_accuracy: 0.8421\n",
      "Epoch 296/469\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 4.3857e-06 - accuracy: 1.0000 - val_loss: 0.8733 - val_accuracy: 0.8421\n",
      "Epoch 297/469\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 4.3532e-06 - accuracy: 1.0000 - val_loss: 0.8728 - val_accuracy: 0.8421\n",
      "Epoch 298/469\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 4.3210e-06 - accuracy: 1.0000 - val_loss: 0.8719 - val_accuracy: 0.8421\n",
      "Epoch 299/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 4.2903e-06 - accuracy: 1.0000 - val_loss: 0.8731 - val_accuracy: 0.8421\n",
      "Epoch 300/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 4.2582e-06 - accuracy: 1.0000 - val_loss: 0.8748 - val_accuracy: 0.8421\n",
      "Epoch 301/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 4.2282e-06 - accuracy: 1.0000 - val_loss: 0.8761 - val_accuracy: 0.8421\n",
      "Epoch 302/469\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 4.1952e-06 - accuracy: 1.0000 - val_loss: 0.8777 - val_accuracy: 0.8421\n",
      "Epoch 303/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 4.1629e-06 - accuracy: 1.0000 - val_loss: 0.8791 - val_accuracy: 0.8421\n",
      "Epoch 304/469\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 4.1352e-06 - accuracy: 1.0000 - val_loss: 0.8814 - val_accuracy: 0.8421\n",
      "Epoch 305/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 4.1042e-06 - accuracy: 1.0000 - val_loss: 0.8837 - val_accuracy: 0.8421\n",
      "Epoch 306/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 4.0769e-06 - accuracy: 1.0000 - val_loss: 0.8843 - val_accuracy: 0.8421\n",
      "Epoch 307/469\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 4.0460e-06 - accuracy: 1.0000 - val_loss: 0.8824 - val_accuracy: 0.8421\n",
      "Epoch 308/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 4.0230e-06 - accuracy: 1.0000 - val_loss: 0.8810 - val_accuracy: 0.8421\n",
      "Epoch 309/469\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 3.9983e-06 - accuracy: 1.0000 - val_loss: 0.8818 - val_accuracy: 0.8421\n",
      "Epoch 310/469\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 3.9722e-06 - accuracy: 1.0000 - val_loss: 0.8848 - val_accuracy: 0.8421\n",
      "Epoch 311/469\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 3.9405e-06 - accuracy: 1.0000 - val_loss: 0.8881 - val_accuracy: 0.8421\n",
      "Epoch 312/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 3.9084e-06 - accuracy: 1.0000 - val_loss: 0.8921 - val_accuracy: 0.8421\n",
      "Epoch 313/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 3.8819e-06 - accuracy: 1.0000 - val_loss: 0.8960 - val_accuracy: 0.8421\n",
      "Epoch 314/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 3.8600e-06 - accuracy: 1.0000 - val_loss: 0.8991 - val_accuracy: 0.8421\n",
      "Epoch 315/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 3.8326e-06 - accuracy: 1.0000 - val_loss: 0.9005 - val_accuracy: 0.8421\n",
      "Epoch 316/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 3.7989e-06 - accuracy: 1.0000 - val_loss: 0.9007 - val_accuracy: 0.8421\n",
      "Epoch 317/469\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 3.7706e-06 - accuracy: 1.0000 - val_loss: 0.9003 - val_accuracy: 0.8421\n",
      "Epoch 318/469\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 3.7440e-06 - accuracy: 1.0000 - val_loss: 0.9010 - val_accuracy: 0.8421\n",
      "Epoch 319/469\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 3.7208e-06 - accuracy: 1.0000 - val_loss: 0.9032 - val_accuracy: 0.8421\n",
      "Epoch 320/469\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 3.6891e-06 - accuracy: 1.0000 - val_loss: 0.9066 - val_accuracy: 0.8421\n",
      "Epoch 321/469\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 3.6639e-06 - accuracy: 1.0000 - val_loss: 0.9102 - val_accuracy: 0.8421\n",
      "Epoch 322/469\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 3.6393e-06 - accuracy: 1.0000 - val_loss: 0.9126 - val_accuracy: 0.8421\n",
      "Epoch 323/469\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 3.6123e-06 - accuracy: 1.0000 - val_loss: 0.9126 - val_accuracy: 0.8421\n",
      "Epoch 324/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 3.5850e-06 - accuracy: 1.0000 - val_loss: 0.9117 - val_accuracy: 0.8421\n",
      "Epoch 325/469\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 3.5557e-06 - accuracy: 1.0000 - val_loss: 0.9115 - val_accuracy: 0.8421\n",
      "Epoch 326/469\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 3.5295e-06 - accuracy: 1.0000 - val_loss: 0.9126 - val_accuracy: 0.8421\n",
      "Epoch 327/469\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 3.5056e-06 - accuracy: 1.0000 - val_loss: 0.9151 - val_accuracy: 0.8421\n",
      "Epoch 328/469\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 3.4820e-06 - accuracy: 1.0000 - val_loss: 0.9174 - val_accuracy: 0.8421\n",
      "Epoch 329/469\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 3.4586e-06 - accuracy: 1.0000 - val_loss: 0.9191 - val_accuracy: 0.8421\n",
      "Epoch 330/469\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 3.4367e-06 - accuracy: 1.0000 - val_loss: 0.9192 - val_accuracy: 0.8421\n",
      "Epoch 331/469\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 3.4104e-06 - accuracy: 1.0000 - val_loss: 0.9178 - val_accuracy: 0.8421\n",
      "Epoch 332/469\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 3.3895e-06 - accuracy: 1.0000 - val_loss: 0.9167 - val_accuracy: 0.8421\n",
      "Epoch 333/469\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 3.3659e-06 - accuracy: 1.0000 - val_loss: 0.9174 - val_accuracy: 0.8421\n",
      "Epoch 334/469\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 3.3422e-06 - accuracy: 1.0000 - val_loss: 0.9202 - val_accuracy: 0.8421\n",
      "Epoch 335/469\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 3.3189e-06 - accuracy: 1.0000 - val_loss: 0.9227 - val_accuracy: 0.8421\n",
      "Epoch 336/469\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 3.2921e-06 - accuracy: 1.0000 - val_loss: 0.9248 - val_accuracy: 0.8421\n",
      "Epoch 337/469\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 3.2678e-06 - accuracy: 1.0000 - val_loss: 0.9277 - val_accuracy: 0.8421\n",
      "Epoch 338/469\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 3.2470e-06 - accuracy: 1.0000 - val_loss: 0.9304 - val_accuracy: 0.8421\n",
      "Epoch 339/469\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 3.2251e-06 - accuracy: 1.0000 - val_loss: 0.9319 - val_accuracy: 0.8421\n",
      "Epoch 340/469\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 3.2023e-06 - accuracy: 1.0000 - val_loss: 0.9326 - val_accuracy: 0.8421\n",
      "Epoch 341/469\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 3.1795e-06 - accuracy: 1.0000 - val_loss: 0.9342 - val_accuracy: 0.8421\n",
      "Epoch 342/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 3.1567e-06 - accuracy: 1.0000 - val_loss: 0.9364 - val_accuracy: 0.8421\n",
      "Epoch 343/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 3.1354e-06 - accuracy: 1.0000 - val_loss: 0.9379 - val_accuracy: 0.8421\n",
      "Epoch 344/469\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 3.1140e-06 - accuracy: 1.0000 - val_loss: 0.9370 - val_accuracy: 0.8421\n",
      "Epoch 345/469\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 3.0869e-06 - accuracy: 1.0000 - val_loss: 0.9336 - val_accuracy: 0.8421\n",
      "Epoch 346/469\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 3.0585e-06 - accuracy: 1.0000 - val_loss: 0.9326 - val_accuracy: 0.8421\n",
      "Epoch 347/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 3.0382e-06 - accuracy: 1.0000 - val_loss: 0.9324 - val_accuracy: 0.8421\n",
      "Epoch 348/469\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 3.0134e-06 - accuracy: 1.0000 - val_loss: 0.9328 - val_accuracy: 0.8421\n",
      "Epoch 349/469\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.9927e-06 - accuracy: 1.0000 - val_loss: 0.9340 - val_accuracy: 0.8421\n",
      "Epoch 350/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.9707e-06 - accuracy: 1.0000 - val_loss: 0.9348 - val_accuracy: 0.8421\n",
      "Epoch 351/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.9487e-06 - accuracy: 1.0000 - val_loss: 0.9340 - val_accuracy: 0.8421\n",
      "Epoch 352/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.9263e-06 - accuracy: 1.0000 - val_loss: 0.9322 - val_accuracy: 0.8421\n",
      "Epoch 353/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.9046e-06 - accuracy: 1.0000 - val_loss: 0.9307 - val_accuracy: 0.8421\n",
      "Epoch 354/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.8841e-06 - accuracy: 1.0000 - val_loss: 0.9294 - val_accuracy: 0.8421\n",
      "Epoch 355/469\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.8626e-06 - accuracy: 1.0000 - val_loss: 0.9294 - val_accuracy: 0.8421\n",
      "Epoch 356/469\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.8430e-06 - accuracy: 1.0000 - val_loss: 0.9300 - val_accuracy: 0.8421\n",
      "Epoch 357/469\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.8225e-06 - accuracy: 1.0000 - val_loss: 0.9277 - val_accuracy: 0.8421\n",
      "Epoch 358/469\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 2.8018e-06 - accuracy: 1.0000 - val_loss: 0.9253 - val_accuracy: 0.8421\n",
      "Epoch 359/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.7819e-06 - accuracy: 1.0000 - val_loss: 0.9253 - val_accuracy: 0.8421\n",
      "Epoch 360/469\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.7641e-06 - accuracy: 1.0000 - val_loss: 0.9269 - val_accuracy: 0.8421\n",
      "Epoch 361/469\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.7451e-06 - accuracy: 1.0000 - val_loss: 0.9283 - val_accuracy: 0.8421\n",
      "Epoch 362/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.7288e-06 - accuracy: 1.0000 - val_loss: 0.9276 - val_accuracy: 0.8421\n",
      "Epoch 363/469\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.7108e-06 - accuracy: 1.0000 - val_loss: 0.9261 - val_accuracy: 0.8421\n",
      "Epoch 364/469\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.6954e-06 - accuracy: 1.0000 - val_loss: 0.9265 - val_accuracy: 0.8421\n",
      "Epoch 365/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.6791e-06 - accuracy: 1.0000 - val_loss: 0.9295 - val_accuracy: 0.8421\n",
      "Epoch 366/469\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.6627e-06 - accuracy: 1.0000 - val_loss: 0.9341 - val_accuracy: 0.8421\n",
      "Epoch 367/469\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.6438e-06 - accuracy: 1.0000 - val_loss: 0.9386 - val_accuracy: 0.8421\n",
      "Epoch 368/469\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.6308e-06 - accuracy: 1.0000 - val_loss: 0.9419 - val_accuracy: 0.8421\n",
      "Epoch 369/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.6122e-06 - accuracy: 1.0000 - val_loss: 0.9426 - val_accuracy: 0.8421\n",
      "Epoch 370/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.5909e-06 - accuracy: 1.0000 - val_loss: 0.9433 - val_accuracy: 0.8421\n",
      "Epoch 371/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.5745e-06 - accuracy: 1.0000 - val_loss: 0.9450 - val_accuracy: 0.8421\n",
      "Epoch 372/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.5589e-06 - accuracy: 1.0000 - val_loss: 0.9477 - val_accuracy: 0.8421\n",
      "Epoch 373/469\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.5393e-06 - accuracy: 1.0000 - val_loss: 0.9505 - val_accuracy: 0.8421\n",
      "Epoch 374/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.5211e-06 - accuracy: 1.0000 - val_loss: 0.9530 - val_accuracy: 0.8421\n",
      "Epoch 375/469\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.5041e-06 - accuracy: 1.0000 - val_loss: 0.9556 - val_accuracy: 0.8421\n",
      "Epoch 376/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.4879e-06 - accuracy: 1.0000 - val_loss: 0.9568 - val_accuracy: 0.8421\n",
      "Epoch 377/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.4704e-06 - accuracy: 1.0000 - val_loss: 0.9558 - val_accuracy: 0.8421\n",
      "Epoch 378/469\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.4541e-06 - accuracy: 1.0000 - val_loss: 0.9536 - val_accuracy: 0.8421\n",
      "Epoch 379/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.4388e-06 - accuracy: 1.0000 - val_loss: 0.9519 - val_accuracy: 0.8421\n",
      "Epoch 380/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.4232e-06 - accuracy: 1.0000 - val_loss: 0.9505 - val_accuracy: 0.8421\n",
      "Epoch 381/469\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.4086e-06 - accuracy: 1.0000 - val_loss: 0.9492 - val_accuracy: 0.8421\n",
      "Epoch 382/469\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.3944e-06 - accuracy: 1.0000 - val_loss: 0.9481 - val_accuracy: 0.8421\n",
      "Epoch 383/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.3792e-06 - accuracy: 1.0000 - val_loss: 0.9455 - val_accuracy: 0.8421\n",
      "Epoch 384/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.3664e-06 - accuracy: 1.0000 - val_loss: 0.9424 - val_accuracy: 0.8421\n",
      "Epoch 385/469\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.3549e-06 - accuracy: 1.0000 - val_loss: 0.9414 - val_accuracy: 0.8421\n",
      "Epoch 386/469\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.3401e-06 - accuracy: 1.0000 - val_loss: 0.9420 - val_accuracy: 0.8421\n",
      "Epoch 387/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.3253e-06 - accuracy: 1.0000 - val_loss: 0.9433 - val_accuracy: 0.8421\n",
      "Epoch 388/469\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 2.3114e-06 - accuracy: 1.0000 - val_loss: 0.9458 - val_accuracy: 0.8421\n",
      "Epoch 389/469\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 2.2971e-06 - accuracy: 1.0000 - val_loss: 0.9492 - val_accuracy: 0.8421\n",
      "Epoch 390/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.2804e-06 - accuracy: 1.0000 - val_loss: 0.9530 - val_accuracy: 0.8421\n",
      "Epoch 391/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.2673e-06 - accuracy: 1.0000 - val_loss: 0.9550 - val_accuracy: 0.8421\n",
      "Epoch 392/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.2519e-06 - accuracy: 1.0000 - val_loss: 0.9552 - val_accuracy: 0.8421\n",
      "Epoch 393/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.2376e-06 - accuracy: 1.0000 - val_loss: 0.9564 - val_accuracy: 0.8421\n",
      "Epoch 394/469\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 2.2238e-06 - accuracy: 1.0000 - val_loss: 0.9584 - val_accuracy: 0.8421\n",
      "Epoch 395/469\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 2.2098e-06 - accuracy: 1.0000 - val_loss: 0.9601 - val_accuracy: 0.8421\n",
      "Epoch 396/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.1981e-06 - accuracy: 1.0000 - val_loss: 0.9609 - val_accuracy: 0.8421\n",
      "Epoch 397/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.1852e-06 - accuracy: 1.0000 - val_loss: 0.9602 - val_accuracy: 0.8421\n",
      "Epoch 398/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.1710e-06 - accuracy: 1.0000 - val_loss: 0.9590 - val_accuracy: 0.8421\n",
      "Epoch 399/469\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 2.1593e-06 - accuracy: 1.0000 - val_loss: 0.9577 - val_accuracy: 0.8421\n",
      "Epoch 400/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.1479e-06 - accuracy: 1.0000 - val_loss: 0.9568 - val_accuracy: 0.8421\n",
      "Epoch 401/469\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 2.1360e-06 - accuracy: 1.0000 - val_loss: 0.9556 - val_accuracy: 0.8421\n",
      "Epoch 402/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.1260e-06 - accuracy: 1.0000 - val_loss: 0.9551 - val_accuracy: 0.8421\n",
      "Epoch 403/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.1145e-06 - accuracy: 1.0000 - val_loss: 0.9548 - val_accuracy: 0.8421\n",
      "Epoch 404/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 2.1028e-06 - accuracy: 1.0000 - val_loss: 0.9538 - val_accuracy: 0.8421\n",
      "Epoch 405/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.0914e-06 - accuracy: 1.0000 - val_loss: 0.9528 - val_accuracy: 0.8421\n",
      "Epoch 406/469\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 2.0803e-06 - accuracy: 1.0000 - val_loss: 0.9539 - val_accuracy: 0.8421\n",
      "Epoch 407/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.0692e-06 - accuracy: 1.0000 - val_loss: 0.9558 - val_accuracy: 0.8421\n",
      "Epoch 408/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.0572e-06 - accuracy: 1.0000 - val_loss: 0.9574 - val_accuracy: 0.8421\n",
      "Epoch 409/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.0462e-06 - accuracy: 1.0000 - val_loss: 0.9573 - val_accuracy: 0.8421\n",
      "Epoch 410/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.0338e-06 - accuracy: 1.0000 - val_loss: 0.9561 - val_accuracy: 0.8421\n",
      "Epoch 411/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 2.0239e-06 - accuracy: 1.0000 - val_loss: 0.9547 - val_accuracy: 0.8421\n",
      "Epoch 412/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 2.0131e-06 - accuracy: 1.0000 - val_loss: 0.9536 - val_accuracy: 0.8421\n",
      "Epoch 413/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 2.0026e-06 - accuracy: 1.0000 - val_loss: 0.9536 - val_accuracy: 0.8421\n",
      "Epoch 414/469\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.9902e-06 - accuracy: 1.0000 - val_loss: 0.9535 - val_accuracy: 0.8421\n",
      "Epoch 415/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.9798e-06 - accuracy: 1.0000 - val_loss: 0.9531 - val_accuracy: 0.8421\n",
      "Epoch 416/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.9697e-06 - accuracy: 1.0000 - val_loss: 0.9533 - val_accuracy: 0.8421\n",
      "Epoch 417/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.9582e-06 - accuracy: 1.0000 - val_loss: 0.9538 - val_accuracy: 0.8421\n",
      "Epoch 418/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.9472e-06 - accuracy: 1.0000 - val_loss: 0.9542 - val_accuracy: 0.8421\n",
      "Epoch 419/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.9373e-06 - accuracy: 1.0000 - val_loss: 0.9539 - val_accuracy: 0.8421\n",
      "Epoch 420/469\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.9269e-06 - accuracy: 1.0000 - val_loss: 0.9530 - val_accuracy: 0.8421\n",
      "Epoch 421/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.9175e-06 - accuracy: 1.0000 - val_loss: 0.9524 - val_accuracy: 0.8421\n",
      "Epoch 422/469\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.9055e-06 - accuracy: 1.0000 - val_loss: 0.9534 - val_accuracy: 0.8421\n",
      "Epoch 423/469\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.8943e-06 - accuracy: 1.0000 - val_loss: 0.9551 - val_accuracy: 0.8421\n",
      "Epoch 424/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.8834e-06 - accuracy: 1.0000 - val_loss: 0.9573 - val_accuracy: 0.8421\n",
      "Epoch 425/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.8733e-06 - accuracy: 1.0000 - val_loss: 0.9593 - val_accuracy: 0.8421\n",
      "Epoch 426/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.8630e-06 - accuracy: 1.0000 - val_loss: 0.9606 - val_accuracy: 0.8421\n",
      "Epoch 427/469\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.8518e-06 - accuracy: 1.0000 - val_loss: 0.9616 - val_accuracy: 0.8421\n",
      "Epoch 428/469\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.8415e-06 - accuracy: 1.0000 - val_loss: 0.9637 - val_accuracy: 0.8421\n",
      "Epoch 429/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.8312e-06 - accuracy: 1.0000 - val_loss: 0.9660 - val_accuracy: 0.8421\n",
      "Epoch 430/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.8205e-06 - accuracy: 1.0000 - val_loss: 0.9669 - val_accuracy: 0.8421\n",
      "Epoch 431/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.8101e-06 - accuracy: 1.0000 - val_loss: 0.9679 - val_accuracy: 0.8421\n",
      "Epoch 432/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.8006e-06 - accuracy: 1.0000 - val_loss: 0.9691 - val_accuracy: 0.8421\n",
      "Epoch 433/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.7904e-06 - accuracy: 1.0000 - val_loss: 0.9703 - val_accuracy: 0.8421\n",
      "Epoch 434/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.7808e-06 - accuracy: 1.0000 - val_loss: 0.9717 - val_accuracy: 0.8421\n",
      "Epoch 435/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7711e-06 - accuracy: 1.0000 - val_loss: 0.9741 - val_accuracy: 0.8421\n",
      "Epoch 436/469\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.7626e-06 - accuracy: 1.0000 - val_loss: 0.9766 - val_accuracy: 0.8421\n",
      "Epoch 437/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.7539e-06 - accuracy: 1.0000 - val_loss: 0.9777 - val_accuracy: 0.8421\n",
      "Epoch 438/469\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.7453e-06 - accuracy: 1.0000 - val_loss: 0.9778 - val_accuracy: 0.8421\n",
      "Epoch 439/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7356e-06 - accuracy: 1.0000 - val_loss: 0.9778 - val_accuracy: 0.8421\n",
      "Epoch 440/469\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.7272e-06 - accuracy: 1.0000 - val_loss: 0.9782 - val_accuracy: 0.8421\n",
      "Epoch 441/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.7186e-06 - accuracy: 1.0000 - val_loss: 0.9797 - val_accuracy: 0.8421\n",
      "Epoch 442/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.7099e-06 - accuracy: 1.0000 - val_loss: 0.9807 - val_accuracy: 0.8421\n",
      "Epoch 443/469\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 1.7013e-06 - accuracy: 1.0000 - val_loss: 0.9813 - val_accuracy: 0.8421\n",
      "Epoch 444/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6927e-06 - accuracy: 1.0000 - val_loss: 0.9816 - val_accuracy: 0.8421\n",
      "Epoch 445/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6843e-06 - accuracy: 1.0000 - val_loss: 0.9810 - val_accuracy: 0.8421\n",
      "Epoch 446/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.6752e-06 - accuracy: 1.0000 - val_loss: 0.9798 - val_accuracy: 0.8421\n",
      "Epoch 447/469\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 1.6665e-06 - accuracy: 1.0000 - val_loss: 0.9783 - val_accuracy: 0.8421\n",
      "Epoch 448/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.6588e-06 - accuracy: 1.0000 - val_loss: 0.9771 - val_accuracy: 0.8421\n",
      "Epoch 449/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6506e-06 - accuracy: 1.0000 - val_loss: 0.9768 - val_accuracy: 0.8421\n",
      "Epoch 450/469\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.6415e-06 - accuracy: 1.0000 - val_loss: 0.9779 - val_accuracy: 0.8421\n",
      "Epoch 451/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6325e-06 - accuracy: 1.0000 - val_loss: 0.9801 - val_accuracy: 0.8421\n",
      "Epoch 452/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.6237e-06 - accuracy: 1.0000 - val_loss: 0.9828 - val_accuracy: 0.8421\n",
      "Epoch 453/469\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.6143e-06 - accuracy: 1.0000 - val_loss: 0.9855 - val_accuracy: 0.8421\n",
      "Epoch 454/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.6059e-06 - accuracy: 1.0000 - val_loss: 0.9872 - val_accuracy: 0.8421\n",
      "Epoch 455/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.5970e-06 - accuracy: 1.0000 - val_loss: 0.9878 - val_accuracy: 0.8421\n",
      "Epoch 456/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.5881e-06 - accuracy: 1.0000 - val_loss: 0.9891 - val_accuracy: 0.8421\n",
      "Epoch 457/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.5800e-06 - accuracy: 1.0000 - val_loss: 0.9907 - val_accuracy: 0.8421\n",
      "Epoch 458/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.5711e-06 - accuracy: 1.0000 - val_loss: 0.9922 - val_accuracy: 0.8421\n",
      "Epoch 459/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.5627e-06 - accuracy: 1.0000 - val_loss: 0.9934 - val_accuracy: 0.8421\n",
      "Epoch 460/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.5551e-06 - accuracy: 1.0000 - val_loss: 0.9950 - val_accuracy: 0.8421\n",
      "Epoch 461/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.5466e-06 - accuracy: 1.0000 - val_loss: 0.9967 - val_accuracy: 0.8421\n",
      "Epoch 462/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5393e-06 - accuracy: 1.0000 - val_loss: 0.9979 - val_accuracy: 0.8421\n",
      "Epoch 463/469\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.5309e-06 - accuracy: 1.0000 - val_loss: 0.9994 - val_accuracy: 0.8421\n",
      "Epoch 464/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5234e-06 - accuracy: 1.0000 - val_loss: 1.0018 - val_accuracy: 0.8421\n",
      "Epoch 465/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.5168e-06 - accuracy: 1.0000 - val_loss: 1.0042 - val_accuracy: 0.8421\n",
      "Epoch 466/469\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.5100e-06 - accuracy: 1.0000 - val_loss: 1.0056 - val_accuracy: 0.8421\n",
      "Epoch 467/469\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.5026e-06 - accuracy: 1.0000 - val_loss: 1.0056 - val_accuracy: 0.8421\n",
      "Epoch 468/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.4955e-06 - accuracy: 1.0000 - val_loss: 1.0054 - val_accuracy: 0.8421\n",
      "Epoch 469/469\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.4894e-06 - accuracy: 1.0000 - val_loss: 1.0060 - val_accuracy: 0.8421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18ef4cd1040>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nn_cl_fun_2():\n",
    "    nn = Sequential()\n",
    "    nn.add(Dense(params_nn_['neurons_1st_hidden'], input_dim=10, activation='relu'))\n",
    "    for i in range(params_nn_['layers1']):\n",
    "        nn.add(Dense(params_nn_['neurons_other_hidden_1'], activation='relu'))\n",
    "    # if params_nn_['dropout'] > 0.5:\n",
    "    #     nn.add(Dropout(params_nn_['dropout_rate'], seed=123))\n",
    "    for i in range(params_nn_['layers2']):\n",
    "        nn.add(Dense(params_nn_['neurons_other_hidden_2'], activation='relu'))\n",
    "    nn.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    nn.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return nn\n",
    "\n",
    "es = EarlyStopping(monitor='accuracy', mode='max', verbose=0, patience=10)\n",
    "nn = KerasClassifier(build_fn=nn_cl_fun_2, epochs=params_nn_['epochs'], batch_size=params_nn_['batch_size'],\n",
    "                         verbose=0)\n",
    "\n",
    "\n",
    "# train_set : validation_set : test_set = 80 : 10 : 10 \n",
    "train_feature_scaled, validation_feature_scaled, train_label, validation_label = train_test_split(train_feature_scaled, train_label, test_size = 0.10,random_state=0)\n",
    "\n",
    "nn.fit(train_feature_scaled, train_label, validation_data=(validation_feature_scaled, validation_label), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7708333134651184"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.score(test_feature_scaled, test_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a67d1e513a63fb5df12a1f88f9fb53c8b960337494b38d9e1ad0fe9c421b1da6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
